# -*- coding: utf-8 -*-
"""test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bwZ14dHnjgb_lygDKPWhQwGhXzUVqGam

# Projet de Prédiction de la Productivité des Employés

## Introduction
Le présent projet vise à développer un modèle de Machine Learning capable de prédire la productivité des employés au sein d'une organisation. La productivité des employés est un facteur clé de la performance globale de l'entreprise, et la capacité à anticiper les variations de cette productivité peut permettre une meilleure gestion des ressources humaines.

## Objectifs
- Mettre en place un modèle prédictif basé sur des données historiques de l'entreprise.
- Analyser les facteurs influençant la productivité des employés.
- Fournir des recommandations pour améliorer la productivité et l'efficacité du personnel.

## Technologies utilisées
Le projet sera développé en utilisant les outils et bibliothèques suivants :
- **Langage de programmation :** Python
- **Environnement de développement :** Google Colab
- **Bibliothèques :** Pandas, NumPy, Scikit-Learn, TensorFlow/Keras

## Données
Les données utilisées pour l'entraînement et le test du modèle ont été téléchargées depuis Kaggle, une plateforme de partage de jeux de données. Ces données comprennent des informations variées telles que le nombre d'absence , les retards, et d'autres métriques pertinentes. Avant d'être utilisées pour entraîner le modèle, ces données seront prétraitées et nettoyées pour garantir leur qualité et leur pertinence.

| Feature                  | Description                                                            | DataType  |
|--------------------------|------------------------------------------------------------------------|-----------|
| Employee Name            | Employee’s full name                                                   | Text      |
| EmpID                    | Employee ID is unique to each employee                                  | Text      |
| MarriedID                | Is the person married (1 or 0 for yes or no)                           | Binary    |
| MaritalStatusID          | Marital status code that matches the text field MaritalDesc            | Integer   |
| EmpStatusID              | Employment status code that matches text field EmploymentStatus        | Integer   |
| DeptID                   | Department ID code that matches the department the employee works in   | Integer   |
| PerfScoreID              | Performance Score code that matches the employee’s most recent performance score | Integer   |
| FromDiversityJobFairID   | Was the employee sourced from the Diversity job fair? 1 or 0 for yes or no | Binary    |
| PayRate                  | The person’s hourly pay rate. All salaries are converted to hourly pay rate | Float     |
| Termd                    | Has this employee been terminated - 1 or 0                              | Binary    |
| PositionID               | An integer indicating the person’s position                             | Integer   |
| Position                 | The text name/title of the position the person has                     | Text      |
| State                    | The state that the person lives in                                      | Text      |
| Zip                      | The zip code for the employee                                           | Text      |
| DOB                      | Date of Birth for the employee                                          | Date      |
| Sex                      | Sex - M or F                                                           | Text      |
| MaritalDesc              | The marital status of the person (divorced, single, widowed, separated, etc) | Text      |
| CitizenDesc              | Label for whether the person is a Citizen or Eligible NonCitizen        | Text      |
| HispanicLatino           | Yes or No field for whether the employee is Hispanic/Latino             | Text      |
| RaceDesc                 | Description/text of the race the person identifies with                  | Text      |
| DateofHire               | Date the person was hired                                               | Date      |
| DateofTermination        | Date the person was terminated, only populated if, in fact, Termd = 1    | Date      |
| TermReason               | A text reason / description for why the person was terminated           | Text      |
| EmploymentStatus         | A description/category of the person’s employment status. Anyone currently working full time = Active | Text      |
| Department               | Name of the department that the person works in                           | Text      |
| ManagerName              | The name of the person’s immediate manager                               | Text      |
| ManagerID                | A unique identifier for each manager                                    | Integer   |
| RecruitmentSource        | The name of the recruitment source where the employee was recruited from | Text      |
| PerformanceScore         | Performance Score text/category (Fully Meets, Partially Meets, PIP, Exceeds) | Text      |
| EngagementSurvey         | Results from the last engagement survey, managed by our external partner | Float     |
| EmpSatisfaction          | A basic satisfaction score between 1 and 5, as reported on a recent employee satisfaction survey | Integer   |
| SpecialProjectsCount     | The number of special projects that the employee worked on during the last 6 months | Integer   |
| LastPerformanceReviewDate | The most recent date of the person’s last performance review            | Date      |
| DaysLateLast30           | The number of times that the employee was late to work during the last 30 days | Integer   |


## Étapes du projet
1. **Collecte des données :** Rassembler des données pertinentes sur la productivité des employés.
2. **Exploration des données :** Analyser et visualiser les données pour comprendre les tendances et les relations.
3. **Prétraitement des données :** Nettoyer les données, gérer les valeurs manquantes et encoder les variables catégorielles.
4. **Entraînement du modèle :** Utiliser un algorithme de Machine Learning pour entraîner le modèle sur les données historiques.
5. **Évaluation du modèle :** Tester la performance du modèle sur un ensemble de données de test et ajuster les paramètres si nécessaire.
6. **Interprétation des résultats :** Analyser les résultats du modèle pour identifier les facteurs les plus influents sur la productivité.

## Conclusion
Ce projet vise à fournir des insights significatifs sur les déterminants de la productivité des employés, permettant ainsi aux organisations de prendre des décisions éclairées pour améliorer leurs performances opérationnelles. Le modèle développé sera déployé sur Google Colab/Github pour assurer une accessibilité et une flexibilité maximales.

# Chargement des bibliothèques nécessaires
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from tabulate import tabulate
from datetime import datetime

"""# Chargement du dataset"""

#from google.colab import drive
#drive.mount('/content/drive')
df = pd.read_csv('HRDataset_v14.csv')

"""Affichage des trois premières lignes du DataFrame pour obtenir un aperçu rapide des données et vérifier si elles sont correctement chargées."""

df.head(3)

"""Affichage des noms des différentes variables ou attributs représentées par les colonnes du DataFrame."""

df.columns

"""#information sur les attribut de dataset

Affichage d'un résumé concis mais informatif du DataFrame afin d'obtenir les détails importants sur sa structure.
"""

df.info()

"""#Formater la colonne DOB"""

character_to_add = '19'
index_to_add_character_after = 6

df['DOB'] = df['DOB'].apply(lambda x: x[:index_to_add_character_after] + character_to_add + x[index_to_add_character_after:])

"""#Modifier le type de la colonne"""

df['DOB'] = pd.to_datetime(df['DOB'])

"""On a convertie la colonne 'DOB', qui représente l'année de naissance, en un format de datetime, pour faciliter les opérations de filtrage, de tri et d'analyse temporelle sur les données.

#Ajouter la colonne Age calculée à partir de la colonne DOB
"""

import datetime

current_year = datetime.datetime.now().year

df['Age'] = current_year - df['DOB'].dt.year

"""On a ajouter une nouvelle colonne 'Age' qui contient l'âge calculé pour chaque entrée en utilisant l'année de naissance 'DOB' et l'année actuelle obtenue avec le module datetime."""

data = df[['Age', 'DOB']]
data.head()

# Filtrer les lignes où la valeur de la colonne 'Age' est inférieure à zéro
data[data['Age'] < 0]

"""#Ajouter la colonne "yearsof work" calculée à partir de la colonne "DateofHire"
"""

from datetime import datetime
df['DateofHire'] = pd.to_datetime(df['DateofHire'], format='%m/%d/%Y')
current_date = datetime.now()
df['YearsOfWork'] = (current_date - df['DateofHire']).dt.days // 365
print(df[['DateofHire', 'YearsOfWork']])

"""On a calculer le nombre d'années de travail 'YearsOfWork' en soustrayant la date d'embauche de chaque entrée de la colonne 'DateofHire' à partir de la date actuelle obtenue en utilisant le module datetime.

# Identification du nombre de lignes et de colonnes
"""

df.shape

"""# Identification du type de variables"""

df.dtypes.value_counts()
df.dtypes.value_counts().plot.pie()

"""# Quelques statistiques basiques à propos du dataset

Affichage d'un résumé statistique des colonnes numériques du DataFrame telles que le nombre d'entrées, la moyenne, l'écart-type, les valeurs minimales et maximales, ainsi que les quartiles (25%, 50% et 75%) des colonnes numériques.
"""

df.describe()

"""# Vérification des informations"""

df.info()

"""#La vérification des valeurs manquantes"""

df.isnull().sum()

"""On peut voir nos modifications effectuer : deux colonnes ont été ajoutées : 'Age' de type entier (int64) et 'YearsOfWork' de type entier (int64). De plus, Les colonnes 'DOB' (date de naissance) et 'DateofHire' (date d'embauche) ont été converties en type datetime64[ns]. Les autres colonnes ont conservé leurs types de données d'origine.

# La vérification des valeurs doubles
"""

df.duplicated().sum()

"""#Quelques informations sur les attributs du dataset"""

palette = {'Male': 'blue', 'Female': 'pink'}
sns.countplot(data=df, x='Sex')

sex_counts = df['Sex'].value_counts()
sex_percentages = df['Sex'].value_counts(normalize=True) * 100

result_df = pd.DataFrame({'Count': sex_counts, 'Percentage': sex_percentages})

print(result_df)

"""# Des statistiques sur les départements"""

df["Department"].value_counts()

sns.countplot(data=df, y='Department')

"""# Des statistiques sur les sources de recrutement"""

df["RecruitmentSource"].value_counts()

sns.countplot(data=df, y='RecruitmentSource')

"""# la distribution de salar entre les employés"""

sns.histplot(df, x='Salary')
plt.xlabel('Salary')
plt.ylabel('Frequency')
plt.title('Salary Distribution')
plt.show()

"""# Des statistiques sur les Position

"""

df['Position'].value_counts()

sns.countplot(df, y='Position')
plt.xlabel('count')
plt.ylabel('Position')
plt.title('Position Distribution')
plt.show()

"""# La relation entre le salare et l'age"""

sns.scatterplot(df, x='Age', y='Salary')
plt.xlabel('Age')
plt.ylabel('Salary')
plt.title('Salary vs Age')
plt.show()

"""#le nombre des employés dans chaque classe de performance"""

sns.countplot(df, x='PerformanceScore')
plt.xlabel('classe de performance')
plt.ylabel('Count')
plt.title('PerformanceScore Distrubution')
plt.show()

counts = df['PerformanceScore'].value_counts()
percentages = df['PerformanceScore'].value_counts(normalize=True) * 100


result_df = pd.DataFrame({'Count': counts, 'Percentage': percentages})

print(result_df)

"""# le nombre d'occurrences de chaque catégorie en fonction de la performance

On va génèrer une série de graphiques à barres pour chaque attribut catégorique dans la liste categorical_columns, montrant le nombre d'occurrences de chaque catégorie en fonction de la variable "PerformanceScore". Cela permet d'obtenir des informations sur la distribution des catégories et de déterminer s'il existe des associations ou des tendances entre les attributs catégoriques et la variable cible.
"""

# Visualisation des attributs catégoriques par rapport à la variable "PerformanceScore" à l'aide de la fonction countplot de Seaborn.
categorical_columns = ['MaritalStatusID', 'GenderID', 'FromDiversityJobFairID', 'PerfScoreID']
for column in categorical_columns:
    plt.figure(figsize=(10, 6))
    sns.countplot(x=column, hue='PerformanceScore', data=df)
    plt.title(f'{column} vs PerformanceScore')
    plt.xlabel(column)
    plt.ylabel('Count')
    plt.xticks(rotation=45)
    plt.legend(title='PerformanceScore')
    plt.show()

"""# Relation entre le sexe et la performance"""

count_data = df.groupby(['PerformanceScore', 'Sex']).size().reset_index(name='Count')

sns.barplot(x='PerformanceScore', y='Count', hue='Sex', data=count_data)

plt.title('Performance Score by Sex')
plt.xlabel('Performance Score')
plt.ylabel('Count')
plt.show()

table = pd.crosstab(index=df['PerformanceScore'], columns=df['Sex'])
print(tabulate(table, tablefmt='fancy_grid', headers='keys'))

table = pd.crosstab(df['Sex'], df['PerformanceScore'], normalize='index') * 100

print(tabulate(table, tablefmt='fancy_grid', headers='keys'))

"""# Relation entre le marital status et la performance"""

count_data = df.groupby(['PerformanceScore', 'MaritalDesc']).size().reset_index(name='Count')

sns.barplot(x='PerformanceScore', y='Count', hue='MaritalDesc', data=count_data)

plt.title('Performance Score by marital status')
plt.xlabel('Performance Score')
plt.ylabel('Count')
plt.show()

table = pd.crosstab(index=df['PerformanceScore'], columns=df['MaritalDesc'])
print(tabulate(table, tablefmt='fancy_grid', headers='keys'))

"""# Relation entre race et la performance"""

count_data = df.groupby(['PerformanceScore', 'RaceDesc']).size().reset_index(name='Count')
plt.figure(figsize=(10, 6))
sns.barplot(x='PerformanceScore', y='Count', hue='RaceDesc', data=count_data)
plt.title('Performance Score by Race')
plt.xlabel('Performance Score')
plt.ylabel('Count')
plt.show()

from tabulate import tabulate
table = pd.crosstab(index=df['PerformanceScore'], columns=df['RaceDesc'])
print(tabulate(table, tablefmt='fancy_grid', headers='keys'))

"""# Relation entre Engagement Survey et la performance




"""

sns.boxplot(x='PerformanceScore', y='EngagementSurvey', data=df)
plt.title('Box Plot of Engagement Survey by Performance Score')
plt.show()

performance_order = ['Exceeds', 'Fully Meets', 'Needs Improvement','PIP']

result_table = df.groupby('PerformanceScore')['EngagementSurvey'].agg(['mean', 'std', 'count', 'min', 'max', lambda x: x.quantile(0.25), lambda x: x.quantile(0.5), lambda x: x.quantile(0.75)]).reset_index()
result_table.rename(columns={'<lambda_0>': '25%', '<lambda_1>': '50%', '<lambda_2>': '75%'}, inplace=True)

print(tabulate(result_table, tablefmt='fancy_grid', headers='keys'))

"""# Relation entre EmpSatisfaction et la performance"""

# Visualisation de l'attribut numérique (EmpSatisfaction) par rapport à PerformanceScore
sns.boxplot(x='PerformanceScore', y='EmpSatisfaction', data=df)
plt.title('Box Plot of EmpSatisfaction by Performance Score')
plt.show()

performance_order = ['Exceeds', 'Fully Meets', 'Needs Improvement','PIP']

result_table = df.groupby('PerformanceScore')['EngagementSurvey'].agg(['mean', 'std', 'count', 'min', 'max', lambda x: x.quantile(0.25), lambda x: x.quantile(0.5), lambda x: x.quantile(0.75)]).reset_index()
result_table.rename(columns={'<lambda_0>': '25%', '<lambda_1>': '50%', '<lambda_2>': '75%'}, inplace=True)

print(tabulate(result_table, tablefmt='fancy_grid', headers='keys'))

"""# Relation entre age et la performance



"""

# Visualisation de l'attribut numérique (Age) par rapport à PerformanceScore
sns.boxplot(x='PerformanceScore', y='Age', data=df)
plt.title('Box Plot of Age by Performance Score')
plt.show()

performance_order = ['Exceeds', 'Fully Meets', 'Needs Improvement','PIP']

result_table = df.groupby('PerformanceScore')['Age'].agg(['mean', 'std', 'count', 'min', 'max', lambda x: x.quantile(0.25), lambda x: x.quantile(0.5), lambda x: x.quantile(0.75)]).reset_index()
result_table.rename(columns={'<lambda_0>': '25%', '<lambda_1>': '50%', '<lambda_2>': '75%'}, inplace=True)

print(tabulate(result_table, tablefmt='fancy_grid', headers='keys'))

"""# Relation entre salary et la performance"""

# Visualisation de l'attribut numérique (Salary) par rapport à PerformanceScore
sns.boxplot(x='PerformanceScore', y='Salary', data=df)
plt.title('Box Plot of Age by Performance Score')
plt.show()

performance_order = ['Exceeds', 'Fully Meets', 'Needs Improvement','PIP']

result_table = df.groupby('PerformanceScore')['Salary'].agg(['mean', 'std', 'count', 'min', 'max', lambda x: x.quantile(0.25), lambda x: x.quantile(0.5), lambda x: x.quantile(0.75)]).reset_index()
result_table.rename(columns={'<lambda_0>': '25%', '<lambda_1>': '50%', '<lambda_2>': '75%'}, inplace=True)

print(tabulate(result_table, tablefmt='fancy_grid', headers='keys'))

"""# Relation entre YearsOfWork et la performance"""

# Visualisation de l'attribut numérique (YearsOfWork) par rapport à PerformanceScore
sns.boxplot(x='PerformanceScore', y='YearsOfWork', data=df)
plt.title('Box Plot of Age by Performance Score')
plt.show()

performance_order = ['Exceeds', 'Fully Meets', 'Needs Improvement','PIP']

result_table = df.groupby('PerformanceScore')['YearsOfWork'].agg(['mean', 'std', 'count', 'min', 'max', lambda x: x.quantile(0.25), lambda x: x.quantile(0.5), lambda x: x.quantile(0.75)]).reset_index()
result_table.rename(columns={'<lambda_0>': '25%', '<lambda_1>': '50%', '<lambda_2>': '75%'}, inplace=True)

print(tabulate(result_table, tablefmt='fancy_grid', headers='keys'))

"""# Relation entre SpecialProjectsCount et performance"""

# Visualisation de l'attribut numérique (SpecialProjectsCount) par rapport à PerformanceScore
plt.figure(figsize=(10, 6))
sns.boxplot(x='PerformanceScore', y='SpecialProjectsCount', data=df)
plt.title('Nombre de projets spéciaux vs PerformanceScore')
plt.xlabel('PerformanceScore')
plt.ylabel('Nombre de projets spéciaux')
plt.show()

"""# Relation entre DaysLateLast30 et la performance"""

# Visualisation de l'attribut numérique (DaysLateLast30) par rapport à PerformanceScore
plt.figure(figsize=(10, 6))
sns.boxplot(x='PerformanceScore', y='DaysLateLast30', data=df)
plt.title('Jours de retard sur les 30 derniers jours vs PerformanceScore')
plt.xlabel('PerformanceScore')
plt.ylabel('Jours de retard sur les 30 derniers jours')
plt.show()

"""# Relation entre les absences et la Performance"""

# Visualisation de l'attribut numérique (Absences) par rapport à PerformanceScore
plt.figure(figsize=(10, 6))
sns.boxplot(x='PerformanceScore', y='Absences', data=df)
plt.title('Absences vs PerformanceScore')
plt.xlabel('PerformanceScore')
plt.ylabel('Absences')
plt.show()

"""# Nouvelle section"""



"""#supprimer les colonees qui nous sont pas necessaire

"""

df.drop(['Sex','Department','Employee_Name', 'EmpID', 'MarriedID', 'MaritalStatusID', 'GenderID',
       'EmpStatusID', 'DeptID', 'PerfScoreID', 'FromDiversityJobFairID','Termd' ,'PositionID','Position','State', 'Zip', 'DOB',
         'CitizenDesc', 'HispanicLatino', 'RaceDesc','DateofHire','DateofTermination', 'TermReason', 'EmploymentStatus',
         'ManagerName', 'ManagerID','RecruitmentSource','LastPerformanceReview_Date'
], axis=1, inplace=True)
df.head()

df.columns

"""#enregistrer le resultat final dans un csv"""

# Specify the path where you want to save the CSV file
csv_file_path = 'final_dataset.csv'

# Export the DataFrame to a CSV file
df.to_csv(csv_file_path, index=False)

from sklearn.model_selection import train_test_split
df_p1, df_p2 = train_test_split(df, test_size=0.3, random_state=42)
df_encoded = pd.get_dummies(df, columns=[ 'MaritalDesc','PerformanceScore'])
print(df_encoded)
df_part1, df_part2 = train_test_split(df_encoded, test_size=0.3, random_state=42)
df_p1.shape

"""#generate new data"""

# Set a random seed for reproducibility
np.random.seed(42)

# Number of samples for each PerformanceScore category
num_samples = 1000

# Define the rules for each PerformanceScore category
rules = {
    'PIP': {
        'EngagementSurvey': (1.12, 3.2),
        'DaysLateLast30': (2, 7),
        'Salary': (45000, 75000),
        'Age': (30, 60),
        'Absences': (3, 25),
        'EmpSatisfaction': (1, 5),
        'YearsOfWork': (5, 17),
        'MaritalDesc': ['Divorced', 'Separated'],
        'SpecialProjectsCount': (0, 6)
    },
    'Needs Improvement': {
        'EngagementSurvey': (2, 4),
        'DaysLateLast30': (2, 4),
        'Salary': (50000, 151250),
        'Age': (32, 59),
        'Absences': (2, 17),
        'EmpSatisfaction': (3, 5),
        'YearsOfWork': (7, 17),
        'MaritalDesc': ['Divorced', 'Separated', 'Widowed'],
        'SpecialProjectsCount': (4, 8)
    },
    'Fully Meets': {
        'EngagementSurvey': (4, 5),
        'DaysLateLast30': (0, 3),
        'Salary': (45000, 225250),
        'Age': (31, 72),
        'Absences': (2, 10),
        'EmpSatisfaction': (4, 5),
        'YearsOfWork': (7, 17),
        'MaritalDesc': ['Married', 'Single'],
        'SpecialProjectsCount': (6, 10)
    },
    'Exceeds': {
        'EngagementSurvey': (4, 5),
        'DaysLateLast30': (0, 3),
        'Salary': (45000, 225250),
        'Age': (31, 72),
        'Absences': (0, 8),
        'EmpSatisfaction': (4.5, 5),
        'YearsOfWork': (7, 17),
        'MaritalDesc': ['Married', 'Single'],
        'SpecialProjectsCount': (10, 15)
    }
}

# Generate synthetic data
data = pd.DataFrame()

for category, params in rules.items():
    temp_dict = {}
    for feature, value_range in params.items():
        if feature == 'MaritalDesc':
            temp_dict[feature] = np.random.choice(value_range, num_samples)
        else:
            values = np.random.uniform(value_range[0], value_range[1], num_samples)
            if feature in ['DaysLateLast30'  ,'Age', 'Salary', 'Absences', 'EmpSatisfaction', 'YearsOfWork', 'SpecialProjectsCount']:
                values = values.round().astype(int)
            elif feature == 'EngagementSurvey':
                values = np.round(values, 2)
            temp_dict[feature] = values


    temp_df = pd.DataFrame(temp_dict)
    temp_df['PerformanceScore'] = category
    data = pd.concat([data, temp_df], ignore_index=True)

# Shuffle the data
data = data.sample(frac=1, random_state=42).reset_index(drop=True)

# Display the generated synthetic dataset
print(data.head())
data.shape

"""#some changement"""

# Load the combined data CSV file
combined_data = data  # Replace 'combined_data.csv' with the actual file path

# Set a random seed for reproducibility
np.random.seed(42)

# Replace MaritalDesc for PIP PerformanceScore
pip_condition = (combined_data['PerformanceScore'] == 'PIP') & (combined_data['MaritalDesc'].isin(['Divorced', 'Separated']))
pip_to_replace = np.random.choice(combined_data[pip_condition].index, size=int(0.15 * sum(pip_condition)), replace=False)
combined_data.loc[pip_to_replace, 'MaritalDesc'] = np.random.choice(['Widowed', 'Married', 'Single'], len(pip_to_replace))

# Replace MaritalDesc for Needs Improvement PerformanceScore
ni_condition = (combined_data['PerformanceScore'] == 'Needs Improvement') & (combined_data['MaritalDesc'].isin(['Divorced', 'Separated', 'Widowed']))
ni_to_replace = np.random.choice(combined_data[ni_condition].index, size=int(0.15 * sum(ni_condition)), replace=False)
combined_data.loc[ni_to_replace, 'MaritalDesc'] = np.random.choice(['Widowed', 'Married', 'Single'], len(ni_to_replace))

# Replace MaritalDesc for Exceeds PerformanceScore
exceeds_condition = (combined_data['PerformanceScore'] == 'Exceeds') & (combined_data['MaritalDesc'].isin(['Married', 'Single']))
exceeds_to_replace = np.random.choice(combined_data[exceeds_condition].index, size=int(0.15 * sum(exceeds_condition)), replace=False)
combined_data.loc[exceeds_to_replace, 'MaritalDesc'] = np.random.choice(['Separated', 'Divorced'], len(exceeds_to_replace))

# Replace MaritalDesc for Fully Meets PerformanceScore
fully_meets_condition = (combined_data['PerformanceScore'] == 'Fully Meets') & (combined_data['MaritalDesc'].isin(['Married', 'Single']))
fully_meets_to_replace = np.random.choice(combined_data[fully_meets_condition].index, size=int(0.15 * sum(fully_meets_condition)), replace=False)
combined_data.loc[fully_meets_to_replace, 'MaritalDesc'] = np.random.choice(['Separated', 'Divorced'], len(fully_meets_to_replace))

# Save the modified data to a new CSV file
combined_data.to_csv('data.csv', index=False)  # Replace 'modified_combined_data.csv' with the desired file name

"""#Codage des variables catégorielles 'One-hot encode'"""

data = pd.read_csv('data.csv')
data_net = pd.concat([df_p1, data], ignore_index=True)
data_net.shape
data_encoded = pd.get_dummies(data, columns=[  'MaritalDesc', 'PerformanceScore'])
#print(data_encoded)
np.random.seed(42)

data = pd.concat([df_part1, data_encoded], ignore_index=True)
df.to_csv('combined_data.csv', index=False)  # Replace 'combined_data.csv' with the desired file name
data_net.head()

df_encoded.columns

"""#Sélection du modèle Random Forests"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

X = data[['Salary', 'EngagementSurvey', 'EmpSatisfaction', 'SpecialProjectsCount',
        'DaysLateLast30', 'Absences', 'Age', 'YearsOfWork',
        'MaritalDesc_Divorced', 'MaritalDesc_Married', 'MaritalDesc_Separated',
        'MaritalDesc_Single', 'MaritalDesc_Widowed']]

y = data[['PerformanceScore_Exceeds', 'PerformanceScore_Fully Meets',
        'PerformanceScore_Needs Improvement', 'PerformanceScore_PIP']]


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
exactitude = accuracy_score(y_test, y_pred)
print(f"Exactitude : {exactitude}")

Xx = df_part2[['Salary', 'EngagementSurvey', 'EmpSatisfaction', 'SpecialProjectsCount',
        'DaysLateLast30', 'Absences', 'Age', 'YearsOfWork',
        'MaritalDesc_Divorced', 'MaritalDesc_Married', 'MaritalDesc_Separated',
        'MaritalDesc_Single', 'MaritalDesc_Widowed']]

Yy = df_part2[['PerformanceScore_Exceeds', 'PerformanceScore_Fully Meets',
        'PerformanceScore_Needs Improvement', 'PerformanceScore_PIP']]

y_val = model.predict(Xx)
exactitude = accuracy_score(Yy, y_val)


exactitude = accuracy_score(Yy, y_val)
print(f"Exactitude validation : {exactitude}")

print("\nClassification Report:")
print(classification_report(Yy, y_val))

dv = pd.read_csv('data.csv')

dv.head()

for col in [ 'MaritalDesc','PerformanceScore']:
    data_net[col] = data_net[col].astype('category')

for col in [ 'MaritalDesc','PerformanceScore']:
    df_p2[col] = df_p2[col].astype('category')

"""## **Installer la bibliothèque BentoML pour le déploiment du modele**"""


"""## L'importation de la **bibliothèque**"""

import bentoml

"""#Sélection du modèle Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

# Assume dv is your DataFrame

# Codons les variables catégorielles en utilisant LabelEncoder pour plus de simplicité
label_encoder = LabelEncoder()
categorical_columns = ['MaritalDesc']
for col in categorical_columns:
    dv[col] = label_encoder.fit_transform(dv[col])



# Caractéristiques (X) et variable cible (y)
X = dv[['Salary', 'MaritalDesc', 'EngagementSurvey', 'EmpSatisfaction',
        'SpecialProjectsCount', 'DaysLateLast30', 'Absences', 'Age', 'YearsOfWork']]
y = dv['PerformanceScore']

# Division train-validation-test
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Choix et entraînement d'un modèle d'arbre de décision
modele_arbre_decision = DecisionTreeClassifier(random_state=42)

# Entraînement du modèle sur l'ensemble d'entraînement
modele_arbre_decision.fit(X_train, y_train)

# Prédiction sur l'ensemble d'entraînement
y_train_pred = modele_arbre_decision.predict(X_train)

# Prédiction sur l'ensemble de validation
y_val_pred = modele_arbre_decision.predict(X_val)

# Calcul de l'exactitude sur l'ensemble d'entraînement
exactitude_train = accuracy_score(y_train, y_train_pred)
print(f"Exactitude sur l'ensemble d'entraînement : {exactitude_train}")

# Calcul de l'exactitude sur l'ensemble de validation
exactitude_val = accuracy_score(y_val, y_val_pred)
print(f"Exactitude sur l'ensemble de validation : {exactitude_val}")

"""# Sauvegarder le model de l'arbre de décision"""

bentoml.sklearn.save_model("modele_arbre_decision", modele_arbre_decision)

"""## Chargement des données"""

X[['Salary', 'MaritalDesc', 'EngagementSurvey', 'EmpSatisfaction',
        'SpecialProjectsCount', 'DaysLateLast30', 'Absences', 'Age', 'YearsOfWork']].head(3)

"""# Chargement du model"""

loaded_model = bentoml.sklearn.load_model("modele_arbre_decision:latest")

loaded_model.predict([[175349, 2, 3.06, 4, 6, 5, 4, 38, 7]])

"""*Le model a prédit que cet employé fictif a comme classe d'appartenance 'Needs Improvement' donc le model arrive à faire des prédiction*

Dans BentoML, la manière recommandée d'exécuter l'inférence de modèles ML en service est via Runner, qui donne à BentoML plus de flexibilité en termes de planification du calcul d'inférence, de mise en lots des demandes d'inférence et d'exploitation des ressources matérielles disponibles. Les modèles sauvegardés peuvent être chargés en tant qu'instance Runner, comme indiqué ci-dessous :
"""

# Create a Runner instance:
modele_arbre_decision_runner = bentoml.sklearn.get("modele_arbre_decision:latest").to_runner()

# Runner#init_local initializes the model in current process, this is meant for development and testing only:
modele_arbre_decision_runner.init_local()

# This should yield the same result as the loaded model:
modele_arbre_decision_runner.predict.run([[175349, 2, 3.06, 4, 6, 5, 4, 38, 7]])

"""### Le résultat est pareil

## La pubication du model
"""

# Commented out IPython magic to ensure Python compatibility.


"""Le démarrage du model de développement"""




"""#Sélection du modèle Regression"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder, StandardScaler

label_encoder = LabelEncoder()
categorical_columns = ['MaritalDesc']
for col in categorical_columns:
    data_net[col] = label_encoder.fit_transform(data_net[col])

label_encoder = LabelEncoder()
categorical_columns = ['MaritalDesc']
for col in categorical_columns:
    df_p2[col] = label_encoder.fit_transform(df_p2[col])

X = data_net[['Salary', 'MaritalDesc', 'EngagementSurvey', 'EmpSatisfaction',
        'SpecialProjectsCount', 'DaysLateLast30', 'Absences', 'Age', 'YearsOfWork']]
y = data_net['PerformanceScore']

# Feature scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X = pd.DataFrame(X_scaled, columns=X.columns)

# Split the data into train, test, and validation sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Logistic Regression model
logistic_regression_model = LogisticRegression(random_state=42, max_iter=1000)
logistic_regression_model.fit(X_train, y_train)

# Predictions on the test set
y_test_pred = logistic_regression_model.predict(X_test)

# Evaluation on the test set
accuracy_test = accuracy_score(y_test, y_test_pred)
print(f"Test Accuracy: {accuracy_test}")

Xx = df_p2[['Salary', 'MaritalDesc', 'EngagementSurvey', 'EmpSatisfaction',
        'SpecialProjectsCount', 'DaysLateLast30', 'Absences', 'Age', 'YearsOfWork']]
yy = df_p2['PerformanceScore']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(Xx)
Xx = pd.DataFrame(X_scaled, columns=Xx.columns)

# Predictions on the validation set
y_validation_pred = logistic_regression_model.predict(Xx)

# Evaluation on the validation set
accuracy_validation = accuracy_score(yy, y_validation_pred)
print(f"Validation Accuracy: {accuracy_validation}")

# Importer la fonction learning_curve de sklearn
from sklearn.model_selection import learning_curve

# Définir les tailles d'entraînement et calculer les scores d'entraînement et de validation
train_sizes, train_scores, val_scores = learning_curve(
    estimator=logistic_regression_model, # Le modèle à évaluer
    X=X, # Les caractéristiques
    y=y, # Les étiquettes
    train_sizes=np.linspace(0.1, 1.0, 10), # Les fractions de données d'entraînement à utiliser
    cv=10, # Le nombre de plis de validation croisée
    scoring="accuracy", # La métrique à utiliser
    random_state=42 # La graine aléatoire pour la reproductibilité
)

# Calculer les moyennes et les écarts-types des scores d'entraînement et de validation
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
val_mean = np.mean(val_scores, axis=1)
val_std = np.std(val_scores, axis=1)

# Tracer les courbes d'exactitude de l'entraînement et de la validation
plt.plot(train_sizes, train_mean, color="blue", marker="o", label="Entraînement")
plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, color="lightblue", alpha=0.5)
plt.plot(train_sizes, val_mean, color="green", marker="s", label="Validation")
plt.fill_between(train_sizes, val_mean + val_std, val_mean - val_std, color="lightgreen", alpha=0.5)

# Ajouter les titres, les étiquettes et la légende au graphique
plt.title("Courbes d'apprentissage pour la régression logistique")
plt.xlabel("Taille de l'entraînement")
plt.ylabel("Exactitude")
plt.legend(loc="lower right")
plt.grid()
plt.show()

print(f"Exactitude de l'entraînement: {train_mean[-1]:.3f}")
print(f"Exactitude de la validation: {val_mean[-1]:.3f}")

X = dv[['Salary',  'MaritalDesc', 'EngagementSurvey', 'EmpSatisfaction',
        'SpecialProjectsCount', 'DaysLateLast30', 'Absences', 'Age', 'YearsOfWork']]
y = dv['PerformanceScore']

# Train a Random Forest model
random_forest_model = RandomForestClassifier(random_state=42)
random_forest_model.fit(X, y)


feature_importance = random_forest_model.feature_importances_


feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})

# Sort the DataFrame by importance in descending order
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)


plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])
plt.xlabel('Importance')
plt.title('Feature Importance')
plt.show()


print("Feature Importance Table:")
print(feature_importance_df)











